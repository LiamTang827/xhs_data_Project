import { NextResponse } from 'next/server'
import { MongoClient } from 'mongodb'
import fs from 'fs'
import path from 'path'
// static fallback (generated by convert script)
import {
  creators as staticCreators,
  creatorEdges as staticCreatorEdges,
  trackClusters as staticTrackClusters,
  trendingKeywordGroups as staticTrendingKeywordGroups,
} from '../../../src/data/creators'

const MONGO_URI = process.env.MONGO_URI
const DB_NAME = process.env.MONGO_DB || 'media_crawler'
const CREATOR_COLLECTION = process.env.CREATOR_COLLECTION || 'xhs_users'

// Prefer snapshots/ + analyses/ from the workspace when available
const WORKSPACE_ROOT = process.cwd()
// Go up one level if we are in the frontend directory
const BASE_DIR = WORKSPACE_ROOT.endsWith('xhs-analyser-frontend') 
  ? path.join(WORKSPACE_ROOT, '..') 
  : WORKSPACE_ROOT

const DATA_DIR = path.join(BASE_DIR, 'backend', 'data')
const CREATORS_DATA_FILE = path.join(DATA_DIR, 'creators_data.json')
const SNAPSHOTS_DIR = path.join(BASE_DIR, 'backend', 'data', 'snapshots')
const ANALYSES_DIR = path.join(BASE_DIR, 'backend', 'data', 'analyses')
const EMBED_SIM_THRESHOLD = parseFloat(process.env.EMBED_SIM_THRESHOLD || '0.6')

let cachedClient: MongoClient | null = null

const normalizeKey = (value?: string | null) => {
  if (value === undefined || value === null) return null
  const raw = String(value).trim()
  if (!raw) return null
  return raw.replace(/\.json$/i, '')
}

async function getClient() {
  if (cachedClient) return cachedClient
  if (!MONGO_URI) throw new Error('MONGO_URI environment variable is not set')
  // Newer mongodb drivers no longer accept legacy options like `useUnifiedTopology`.
  // Create client with the connection string only and let the driver pick defaults.
  const client = new MongoClient(MONGO_URI)
  await client.connect()
  cachedClient = client
  return client
}

function buildFromSnapshots() {
  // Read snapshots to build creators metadata
  if (!fs.existsSync(SNAPSHOTS_DIR)) {
    throw new Error(`Snapshots dir not found: ${SNAPSHOTS_DIR}`)
  }
  const files = fs.readdirSync(SNAPSHOTS_DIR).filter((f) => f.endsWith('.json'))
  const creators: any[] = []
  const idByNickname: Record<string, string> = {}

  // group snapshots by creator key (prefer nickname or filename base)
  const groups: Record<string, Array<{ fn: string; date: Date; obj: any }>> = {}
  for (const fn of files) {
    try {
      const raw = fs.readFileSync(path.join(SNAPSHOTS_DIR, fn), 'utf8')
      const obj = JSON.parse(raw)
      // derive date from filename pattern or snapshot_time or file mtime
      let date: Date | null = null
      const m = fn.match(/(.+?)_(\d{4}-\d{2}-\d{2})(?:.*)?\.json$/)
      if (m) {
        try { date = new Date(m[2]) } catch (e) { date = null }
      }
      if (!date && obj && obj.snapshot_time) {
        try { date = new Date(obj.snapshot_time) } catch (e) { date = null }
      }
      if (!date) {
        const stat = fs.statSync(path.join(SNAPSHOTS_DIR, fn))
        date = stat.mtime
      }

      const user = obj.user || {}
      const name = user.nickname || user.name || (m ? m[1] : fn.replace(/\.json$/, ''))
      const key = String(name || fn)
      groups[key] = groups[key] || []
      groups[key].push({ fn, date: date as Date, obj })
    } catch (e: any) {
      console.warn('[api/creators] skip invalid snapshot', fn, e?.message ?? String(e))
    }
  }

  // influence index formula weights
  const WEIGHT_FOLLOWERS = 0.6
  const WEIGHT_INTERACTION = 0.4

  // process groups
  for (const [key, entries] of Object.entries(groups)) {
    // sort by date ascending
    entries.sort((a, b) => a.date.getTime() - b.date.getTime())

    // build time series
    const indexSeries: Array<any> = []
    for (const e of entries) {
      const u = e.obj.user || {}
      const followers = Number(u.fans || u.followers || 0)
      const interaction = Number(u.interaction || u.engagement || 0)
      const influence = Math.round((followers * WEIGHT_FOLLOWERS) + (interaction * WEIGHT_INTERACTION))
      const ts = e.date.getTime()
      indexSeries.push({ 
        time: e.obj.snapshot_time || e.date.toISOString(), 
        followers, 
        interaction, 
        influence,
        ts,
        value: influence
      })
    }

    // latest snapshot becomes main node
    const latestObj = entries[entries.length - 1].obj
    const userLatest = latestObj.user || {}
    const nodeId = userLatest.user_id || userLatest.userId || userLatest.id || key
    const nodeName = userLatest.nickname || userLatest.name || key

    const node: any = {
      id: nodeId,
      name: nodeName,
      followers: Number(userLatest.fans || userLatest.followers || 0),
      engagementIndex: Number(userLatest.interaction || userLatest.engagement || 0),
      primaryTrack: (latestObj.content_topics && latestObj.content_topics[0]) || '其他',
      contentForm: '',
      recentKeywords: [],
      position: { x: 0, y: 0 },
      avatar: userLatest.avatar || '',
      ipLocation: userLatest.ip_location || userLatest.ipLocation || '',
      desc: userLatest.desc || '',
      indexSeries,
    }

    creators.push(node)

    const registerMapping = (value?: string | null) => {
      if (value === undefined || value === null) return
      const raw = String(value).trim()
      if (!raw) return
      idByNickname[raw] = node.id
      const lowered = raw.toLowerCase()
      if (lowered !== raw) {
        idByNickname[lowered] = node.id
      }
      if (!raw.toLowerCase().endsWith('.json')) {
        idByNickname[`${raw}.json`] = node.id
        idByNickname[`${lowered}.json`] = node.id
      }
      const normalized = normalizeKey(raw)
      if (normalized && normalized !== raw) {
        idByNickname[normalized] = node.id
        const normalizedLower = normalized.toLowerCase()
        if (normalizedLower !== normalized) {
          idByNickname[normalizedLower] = node.id
        }
        if (!normalizedLower.endsWith('.json')) {
          idByNickname[`${normalized}.json`] = node.id
          idByNickname[`${normalizedLower}.json`] = node.id
        }
      }
    }

    registerMapping(nodeName)
    registerMapping(nodeId)
  }

  // Build edges using embedding files when available
  const edges: any[] = []
  if (fs.existsSync(ANALYSES_DIR)) {
    const embFiles = fs.readdirSync(ANALYSES_DIR).filter((f) => f.endsWith('__embedding.json'))
    const embeddings: Record<string, number[]> = {}
    for (const ef of embFiles) {
      try {
        const raw = fs.readFileSync(path.join(ANALYSES_DIR, ef), 'utf8')
        const obj = JSON.parse(raw)
        // source is filename like Nickname__embedding.json
        const srcRaw = obj.source || ef.replace(/__embedding.json$/, '')
        const normalizedSrc = normalizeKey(srcRaw)
        const lowerSrc = typeof srcRaw === 'string' ? srcRaw.toLowerCase() : undefined
        const id = (typeof srcRaw === 'string' && idByNickname[srcRaw])
          || (lowerSrc ? idByNickname[lowerSrc] : undefined)
          || (normalizedSrc ? idByNickname[normalizedSrc] : undefined)
          || (normalizedSrc ? idByNickname[normalizedSrc.toLowerCase()] : undefined)
          || (normalizedSrc || (typeof srcRaw === 'string' ? srcRaw : String(srcRaw)))

        const hasCreator = creators.some((creator) => creator.id === id)
        if (!hasCreator) {
          console.warn('[api/creators] embedding source has no matching creator node:', srcRaw, 'normalized:', normalizedSrc)
          continue
        }

        if (Array.isArray(obj.embedding)) embeddings[id] = obj.embedding.map((x: any) => Number(x))
        else console.warn('[api/creators] missing embedding array for', srcRaw)
      } catch (e: any) {
        console.warn('[api/creators] skip invalid embedding', ef, e?.message ?? String(e))
      }
    }

    const ids = Object.keys(embeddings)
    for (let i = 0; i < ids.length; i++) {
      for (let j = i + 1; j < ids.length; j++) {
        const a = embeddings[ids[i]]
        const b = embeddings[ids[j]]
        if (!a || !b || a.length !== b.length) continue
        // cosine similarity
        let dot = 0, na = 0, nb = 0
        for (let k = 0; k < a.length; k++) { dot += a[k]*b[k]; na += a[k]*a[k]; nb += b[k]*b[k] }
        const sim = dot / (Math.sqrt(na) * Math.sqrt(nb) || 1)
        if (sim >= EMBED_SIM_THRESHOLD) {
          edges.push({ source: ids[i], target: ids[j], weight: Math.round(sim*100)/100, types: { style: 1 } })
        }
      }
    }
  }

  // build trackClusters
  const trackClusters: Record<string, string[]> = {}
  for (const c of creators) {
    const k = c.primaryTrack || '其他'
    trackClusters[k] = trackClusters[k] || []
    trackClusters[k].push(c.id)
  }

  return { creators, creatorEdges: edges, trackClusters, trendingKeywordGroups: [] }
}

export async function GET(request: Request) {
  try {
    console.log('[DEBUG] BASE_DIR:', BASE_DIR)
    console.log('[DEBUG] CREATORS_DATA_FILE:', CREATORS_DATA_FILE)
    console.log('[DEBUG] File exists:', fs.existsSync(CREATORS_DATA_FILE))
    
    // Priority 1: Use pre-generated creators_data.json
    if (fs.existsSync(CREATORS_DATA_FILE)) {
      console.log('✅ Loading from creators_data.json')
      const raw = fs.readFileSync(CREATORS_DATA_FILE, 'utf8')
      const data = JSON.parse(raw)
      console.log('[DEBUG] Loaded data:', { 
        creatorsCount: data.creators?.length, 
        edgesCount: data.creatorEdges?.length 
      })
      return NextResponse.json({ source: 'creators_data.json', ...data })
    }

    // Priority 2: Build from snapshots folder (user requested snapshots -> frontend)
    try {
      console.log('[api/creators] Checking snapshots dir:', SNAPSHOTS_DIR)
      if (fs.existsSync(SNAPSHOTS_DIR)) {
        const files = fs.readdirSync(SNAPSHOTS_DIR).filter((f) => f.endsWith('.json'))
        if (files.length > 0) {
          console.log('[api/creators] Found snapshots, building data...')
          const { creators, creatorEdges, trackClusters, trendingKeywordGroups } = buildFromSnapshots()
          return NextResponse.json({ source: 'snapshots', creators, creatorEdges, trackClusters, trendingKeywordGroups })
        }
      } else {
        console.log('[api/creators] Snapshots dir does not exist')
      }
    } catch (e: any) {
      console.warn('[api/creators] failed to read snapshots dir', e?.message ?? String(e))
    }

    // if MONGO not configured, return static converted data immediately
    if (!process.env.MONGO_URI) {
      console.warn('[api/creators] MONGO_URI not configured, returning static data')
      return NextResponse.json({ source: 'static', mongoConfigured: false, creators: staticCreators, creatorEdges: staticCreatorEdges, trackClusters: staticTrackClusters, trendingKeywordGroups: staticTrendingKeywordGroups })
    }

    const client = await getClient()
    const db = client.db(DB_NAME)
    const coll = db.collection(CREATOR_COLLECTION)

    // Simple query: return up to 200 creators, sorted by fans if available
    const docs = await coll.find({}).sort({ fans: -1 }).limit(200).toArray()
    const totalCount = await coll.countDocuments()

    const creators = docs.map((doc: any) => ({
      id: doc.user_id || doc._id?.toString(),
      name: doc.nickname || '',
      followers: Number(doc.fans || doc.followers || 0),
      engagementIndex: Number(doc.interaction || doc.engagement || 0),
      primaryTrack: doc.primaryTrack || '其他',
      contentForm: doc.contentForm || '创作者',
      recentKeywords: Array.isArray(doc.tag_list) ? doc.tag_list : (doc.tag_list ? JSON.parse(doc.tag_list || '[]') : []),
      position: { x: 0, y: 0 },
      avatar: doc.avatar || '',
      ipLocation: doc.ip_location || '',
      desc: doc.desc || '',
      redId: doc.redId || '',
      // expose optional time-series snapshots if available
      indexSeries: doc.snapshots || doc.indexSeries || undefined,
    }))

    // generate simple edges similar to the original convert script
    const creatorEdges: any[] = []
    for (let i = 0; i < creators.length; i++) {
      for (let j = i + 1; j < creators.length; j++) {
        const a = creators[i]
        const b = creators[j]
        const same = a.primaryTrack === b.primaryTrack
        const should = same ? Math.random() > 0.4 : Math.random() > 0.8
        if (should) {
          const weight = parseFloat((0.3 + Math.random() * 0.5).toFixed(2))
          creatorEdges.push({ source: a.id, target: b.id, weight, types: { keyword: 0, audience: 0, style: 0 } })
        }
      }
    }

    // build trackClusters
    const trackClusters: Record<string, string[]> = {}
    creators.forEach((c) => {
      const k = c.primaryTrack || '其他'
      trackClusters[k] = trackClusters[k] || []
      trackClusters[k].push(c.id)
    })

    const trendingKeywordGroups: any[] = []

    const sampleId = creators.length > 0 ? creators[0].id : null
    return NextResponse.json({ source: 'mongo', mongoConfigured: true, count: totalCount, sampleId, creators, creatorEdges, trackClusters, trendingKeywordGroups })
  } catch (err: any) {
    // log full error for easier debugging in dev
    try {
      console.error('[api/creators] Error:', err && err.stack ? err.stack : err)
    } catch (e) {
      console.error('[api/creators] Error (failed to print stack)', String(err))
    }

    // avoid leaking sensitive values (don't echo MONGO_URI), but report whether it's set
    const mongoConfigured = !!process.env.MONGO_URI
    // fallback to static data if available
    try {
      console.warn('[api/creators] Falling back to static creators due to error')
      return NextResponse.json({ source: 'static', mongoConfigured, creators: staticCreators, creatorEdges: staticCreatorEdges, trackClusters: staticTrackClusters, trendingKeywordGroups: staticTrendingKeywordGroups })
    } catch (e) {
      return NextResponse.json({ error: String(err.message || err), mongoConfigured }, { status: 500 })
    }
  }
}
