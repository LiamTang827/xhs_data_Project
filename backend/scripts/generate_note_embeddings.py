#!/usr/bin/env python3
"""
æ‰¹é‡ä¸ºæ‰€æœ‰ç¬”è®°ç”Ÿæˆ embedding å‘é‡

è¯»å– user_snapshots é›†åˆä¸­çš„æ‰€æœ‰ç¬”è®°ï¼Œä½¿ç”¨ BAAI/bge-small-zh-v1.5 æ¨¡å‹
ç”Ÿæˆ 512 ç»´ embeddingï¼Œå­˜å…¥ note_embeddings é›†åˆã€‚

ç”¨æ³•ï¼š
    cd backend
    source ../.venv/bin/activate
    python scripts/generate_note_embeddings.py

å‚æ•°ï¼š
    --batch-size    æ¯æ‰¹ç¼–ç çš„ç¬”è®°æ•°ï¼ˆé»˜è®¤ 64ï¼‰
    --force         å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰ï¼ˆè¦†ç›–å·²æœ‰ï¼‰
"""

import sys
import time
import argparse
from pathlib import Path

# ç¡®ä¿èƒ½ import backend åŒ…
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
from database.connection import get_database
from core.config import settings


def load_embedding_model():
    """åŠ è½½æœ¬åœ° FlagModel"""
    print(f"ğŸ“¦ åŠ è½½ embedding æ¨¡å‹: {settings.EMBEDDING_MODEL}")
    t0 = time.time()
    from FlagEmbedding import FlagModel
    model = FlagModel(
        settings.EMBEDDING_MODEL,
        query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
        use_fp16=True
    )
    print(f"   âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - t0:.1f}s)")
    return model


def extract_notes_from_snapshots(db) -> list:
    """ä» user_snapshots æå–æ‰€æœ‰ç¬”è®°ï¼Œå¹¶å…³è”ç”¨æˆ·ä¿¡æ¯"""
    print("\nğŸ“‹ ä» user_snapshots æå–ç¬”è®°...")

    snapshots = list(db.user_snapshots.find({}, {
        "user_id": 1, "notes": 1, "_id": 0
    }))
    print(f"   æ‰¾åˆ° {len(snapshots)} ä¸ªç”¨æˆ·å¿«ç…§")

    # é¢„åŠ è½½ç”¨æˆ·ä¿¡æ¯
    profiles = {}
    for p in db.user_profiles.find({}, {
        "user_id": 1, "nickname": 1, "basic_info": 1, "_id": 0
    }):
        uid = p.get("user_id", "")
        profiles[uid] = {
            "nickname": p.get("nickname", ""),
            "avatar": p.get("basic_info", {}).get("avatar", "") if isinstance(p.get("basic_info"), dict) else "",
        }

    all_notes = []
    for snap in snapshots:
        uid = snap.get("user_id", "")
        notes = snap.get("notes", [])
        user_info = profiles.get(uid, {"nickname": "", "avatar": ""})

        for note in notes:
            note_id = note.get("id") or note.get("note_id") or ""
            if not note_id:
                continue

            title = note.get("title", "")
            desc = note.get("desc", "")

            # è‡³å°‘è¦æœ‰æ ‡é¢˜æˆ–æè¿°
            if not title and not desc:
                continue

            likes = note.get("likes", 0) or 0
            collected = note.get("collected_count", 0) or 0
            comments = note.get("comments_count", 0) or 0
            shares = note.get("share_count", 0) or 0
            create_time = note.get("create_time", 0) or 0

            # ç»¼åˆäº’åŠ¨æŒ‡æ•° = likes + collected*2 + comments*3 + shares*4
            engagement = likes + collected * 2 + comments * 3 + shares * 4

            all_notes.append({
                "note_id": note_id,
                "user_id": uid,
                "title": title,
                "desc": desc,
                "likes": likes,
                "collected_count": collected,
                "comments_count": comments,
                "share_count": shares,
                "engagement_score": float(engagement),
                "nickname": user_info["nickname"],
                "avatar": user_info["avatar"],
                "note_create_time": create_time,
                # ç”¨äºç¼–ç çš„æ–‡æœ¬
                "_embed_text": f"{title} {desc}".strip(),
            })

    print(f"   æå–åˆ° {len(all_notes)} æ¡æœ‰æ•ˆç¬”è®°")
    return all_notes


def generate_embeddings(model, notes: list, batch_size: int = 64) -> list:
    """æ‰¹é‡ç”Ÿæˆ embedding"""
    print(f"\nğŸ”„ æ‰¹é‡ç”Ÿæˆ embedding (batch_size={batch_size})...")

    texts = [n["_embed_text"] for n in notes]
    all_embeddings = []

    total_batches = (len(texts) + batch_size - 1) // batch_size
    t0 = time.time()

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        batch_num = i // batch_size + 1

        vecs = model.encode(batch_texts)  # numpy array (batch, dim)
        if hasattr(vecs, "tolist"):
            vecs_list = vecs.tolist()
        else:
            vecs_list = np.array(vecs).tolist()

        all_embeddings.extend(vecs_list)

        elapsed = time.time() - t0
        rate = (i + len(batch_texts)) / elapsed if elapsed > 0 else 0
        print(f"   [{batch_num}/{total_batches}] "
              f"å·²ç¼–ç  {i + len(batch_texts)}/{len(texts)} "
              f"({rate:.1f} notes/s)")

    print(f"   âœ… ç¼–ç å®Œæˆï¼Œæ€»è€—æ—¶ {time.time() - t0:.1f}s")
    return all_embeddings


def save_to_mongodb(db, notes: list, embeddings: list, force: bool = False):
    """å†™å…¥ note_embeddings é›†åˆ"""
    print(f"\nğŸ’¾ å†™å…¥ MongoDB note_embeddings é›†åˆ...")

    collection = db.note_embeddings

    # å¦‚æœä¸ forceï¼Œå…ˆæ£€æŸ¥å·²å­˜åœ¨çš„
    existing_ids = set()
    if not force:
        existing = collection.find({}, {"note_id": 1, "_id": 0})
        existing_ids = {doc["note_id"] for doc in existing}
        print(f"   å·²å­˜åœ¨ {len(existing_ids)} æ¡ï¼Œè·³è¿‡")

    from pymongo import UpdateOne
    operations = []
    skipped = 0

    for note, emb in zip(notes, embeddings):
        if not force and note["note_id"] in existing_ids:
            skipped += 1
            continue

        doc = {
            "note_id": note["note_id"],
            "user_id": note["user_id"],
            "platform": "xiaohongshu",
            "title": note["title"],
            "desc": note["desc"],
            "embedding": emb,
            "model": settings.EMBEDDING_MODEL,
            "dimension": settings.EMBEDDING_DIMENSION,
            "likes": note["likes"],
            "collected_count": note["collected_count"],
            "comments_count": note["comments_count"],
            "share_count": note["share_count"],
            "engagement_score": note["engagement_score"],
            "nickname": note["nickname"],
            "avatar": note["avatar"],
            "note_create_time": note["note_create_time"],
        }

        operations.append(UpdateOne(
            {"note_id": note["note_id"]},
            {"$set": doc, "$setOnInsert": {"created_at": __import__("datetime").datetime.now()}},
            upsert=True
        ))

    if operations:
        # åˆ†æ‰¹å†™å…¥
        batch = 500
        total_upserted = 0
        total_modified = 0
        for i in range(0, len(operations), batch):
            result = collection.bulk_write(operations[i:i + batch])
            total_upserted += result.upserted_count
            total_modified += result.modified_count
            print(f"   æ‰¹æ¬¡ {i // batch + 1}: "
                  f"æ–°å¢ {result.upserted_count}, æ›´æ–° {result.modified_count}")

        print(f"\n   âœ… å†™å…¥å®Œæˆ: æ–°å¢ {total_upserted}, æ›´æ–° {total_modified}, è·³è¿‡ {skipped}")
    else:
        print(f"   â„¹ï¸  æ²¡æœ‰éœ€è¦å†™å…¥çš„æ•°æ® (è·³è¿‡ {skipped})")


def create_note_indexes(db):
    """åˆ›å»ºå¿…è¦çš„ç´¢å¼•"""
    print("\nğŸ“Š åˆ›å»ºç´¢å¼•...")
    collection = db.note_embeddings

    indexes = [
        ("note_id_unique", [("note_id", 1)], {"unique": True}),
        ("user_id", [("user_id", 1)], {}),
        ("engagement_score_desc", [("engagement_score", -1)], {}),
        ("note_create_time_desc", [("note_create_time", -1)], {}),
    ]

    for name, keys, opts in indexes:
        try:
            collection.create_index(keys, name=name, **opts)
            print(f"   âœ… {name}")
        except Exception as e:
            if "already exists" in str(e):
                print(f"   â„¹ï¸  {name} (å·²å­˜åœ¨)")
            else:
                print(f"   âŒ {name}: {e}")


def main():
    parser = argparse.ArgumentParser(description="ä¸ºç¬”è®°ç”Ÿæˆ embedding å‘é‡")
    parser.add_argument("--batch-size", type=int, default=64, help="æ¯æ‰¹ç¼–ç æ•°é‡")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶è¦†ç›–å·²æœ‰ embedding")
    args = parser.parse_args()

    print("=" * 60)
    print("ğŸš€ ç¬”è®° Embedding æ‰¹é‡ç”Ÿæˆå·¥å…·")
    print("=" * 60)
    print(f"  æ¨¡å‹: {settings.EMBEDDING_MODEL}")
    print(f"  ç»´åº¦: {settings.EMBEDDING_DIMENSION}")
    print(f"  æ‰¹å¤§å°: {args.batch_size}")
    print(f"  å¼ºåˆ¶è¦†ç›–: {args.force}")

    t_total = time.time()

    # 1. è¿æ¥æ•°æ®åº“
    db = get_database()

    # 2. æå–ç¬”è®°
    notes = extract_notes_from_snapshots(db)
    if not notes:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬”è®°ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
        return

    # 3. åŠ è½½æ¨¡å‹
    model = load_embedding_model()

    # 4. ç”Ÿæˆ embedding
    embeddings = generate_embeddings(model, notes, batch_size=args.batch_size)

    # 5. å†™å…¥ MongoDB
    save_to_mongodb(db, notes, embeddings, force=args.force)

    # 6. åˆ›å»ºç´¢å¼•
    create_note_indexes(db)

    # 7. ç»Ÿè®¡
    final_count = db.note_embeddings.count_documents({})
    print(f"\n{'=' * 60}")
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"  note_embeddings é›†åˆ: {final_count} æ¡")
    print(f"  æ€»è€—æ—¶: {time.time() - t_total:.1f}s")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    main()
