#!/usr/bin/env python3
"""åˆ†æå¿«ç…§ï¼šä½¿ç”¨ GPT-4o ç”Ÿæˆç”¨æˆ·ç”»åƒå¹¶è®¡ç®— embeddings çš„è„šæœ¬ã€‚

ç”¨æ³•ï¼š
    # é»˜è®¤ï¼šä½¿ç”¨ snapshots/ ç›®å½•ä¸‹æœ€æ–°çš„å¿«ç…§
    python3 analyze_snapshot.py

    # æŒ‡å®šå¿«ç…§è·¯å¾„å’Œè¾“å‡ºç›®å½•
    python3 analyze_snapshot.py --snapshot snapshots/æ‰€é•¿æ—ç§‘æ™®_2025-11-18.json --out analyses

ä¾èµ–ï¼š
    pip3 install requests

è¿è¡Œå‰ç¯å¢ƒå˜é‡ï¼š
    éœ€è¦åœ¨ç¯å¢ƒä¸­è®¾ç½® `OPENAI_API_KEY` æˆ– Deepseek å¯¹åº”çš„ KEYï¼ˆè¯¦è§ä¸‹æ–‡ï¼‰
"""

import os
import json
import argparse
from glob import glob
from pathlib import Path
from datetime import datetime
import requests
import re
from typing import List, Dict, Any
import numpy as np
from FlagEmbedding import FlagModel


OPENAI_CHAT_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_EMBED_URL = "https://api.openai.com/v1/embeddings"
CHAT_MODEL = "gpt-4o"
EMBED_MODEL = "text-embedding-3-small"

# å¯åœ¨æ­¤å¤„ç›´æ¥å¡«å†™ API Key æˆ– URLï¼ˆä»…ç”¨äºæœ¬åœ°å¿«é€Ÿæµ‹è¯•ï¼›ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–æ›´å®‰å…¨çš„å¯†é’¥ç®¡ç†ï¼‰
DEFAULT_OPENAI_API_KEY = ""            # <-- åœ¨è¿™é‡Œå¡«å…¥ OpenAI API Keyï¼ˆå¯é€‰ï¼‰
DEFAULT_DEEPSEEK_API_KEY = None  # ä»ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY è¯»å–
DEFAULT_DEEPSEEK_CHAT_URL = "https://api.deepseek.com/v1/chat/completions"         # <-- åœ¨è¿™é‡Œå¡«å…¥ Deepseek chat endpointï¼ˆå¯é€‰ï¼‰
DEFAULT_DEEPSEEK_EMBED_URL = "https://api.deepseek.com/v1/embeddings"        # <-- åœ¨è¿™é‡Œå¡«å…¥ Deepseek embeddings endpointï¼ˆå¯é€‰ï¼‰

# Deepseek æ”¯æŒï¼šå½“ provider ä¸º 'deepseek' æ—¶ï¼Œè„šæœ¬ä¼šè¯»å–ä¸‹åˆ—ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨ä¸Šé¢çš„é»˜è®¤å€¼
DEEPSEEK_CHAT_URL = os.environ.get("DEEPSEEK_CHAT_URL", DEFAULT_DEEPSEEK_CHAT_URL)
DEEPSEEK_EMBED_URL = os.environ.get("DEEPSEEK_EMBED_URL", DEFAULT_DEEPSEEK_EMBED_URL)



def find_latest_snapshot(snap_dir: Path) -> Path:
    """è¿”å›æŒ‡å®šç›®å½•ä¸‹æŒ‰ä¿®æ”¹æ—¶é—´æ’åºçš„æœ€æ–° .json å¿«ç…§è·¯å¾„ï¼Œæ‰¾ä¸åˆ°åˆ™è¿”å› Noneã€‚"""
    files = sorted(snap_dir.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[0] if files else None


def load_snapshot(path: Path) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def build_prompt_for_profile(user_desc: str, notes: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """æ„å»ºå‘é€ç»™èŠå¤©æ¨¡å‹çš„ promptï¼ˆä»¥ messages åˆ—è¡¨å½¢å¼è¿”å›ï¼‰ã€‚

    åŒ…å«ç”¨æˆ·æè¿°ï¼ˆuser_descï¼‰å’Œè‹¥å¹²æ¡ç¬”è®°çš„ title/desc ä½œä¸ºæ ·ä¾‹ã€‚
    æ³¨æ„ï¼šTikHub APIè¿”å›çš„ç¬”è®°æ•°æ®æ²¡æœ‰tag_listå­—æ®µï¼Œéœ€è¦AIä»æ ‡é¢˜å’Œæè¿°ä¸­æå–è¯é¢˜ã€‚
    """
    # ç»„è£…ç¬”è®°å†…å®¹ï¼štitle + descï¼ˆæ²¡æœ‰tagsï¼‰
    sample_notes = []
    for n in notes[:50]:
        title = n.get('title', '')
        desc = n.get('desc', '')
        # æå–äº’åŠ¨æ•°æ®ä½œä¸ºå‚è€ƒ
        likes = n.get('likes', 0)
        collects = n.get('collected_count', 0)
        t = f"æ ‡é¢˜: {title}\næè¿°: {desc}\näº’åŠ¨: ğŸ‘{likes} ğŸ’¾{collects}"
        sample_notes.append(t)

    notes_text = "\n\n".join(sample_notes)

    system = (
        "ä½ æ˜¯ä¸€ä¸ªå°çº¢ä¹¦å†…å®¹åˆ†æä¸“å®¶ã€‚è¯·ä»ç”¨æˆ·çš„ç¬”è®°ä¸­æå–ï¼š\n"
        "1. **ç”¨æˆ·ç”»åƒ(user_style)**ï¼šåŒ…å«personaï¼ˆåˆ›ä½œè€…æ€§æ ¼/å®šä½ï¼Œ1-2å¥ï¼‰ã€toneï¼ˆè¯­æ°”é£æ ¼ï¼‰ã€interestsï¼ˆå…´è¶£å…³é”®è¯åˆ—è¡¨ï¼‰\n"
        "2. **å†…å®¹ä¸»é¢˜(content_topic)**ï¼š5-8ä¸ªæœ€æ ¸å¿ƒçš„è¯é¢˜å…³é”®è¯ï¼ˆç”¨äºä½œä¸º'æµé‡å¯†ç 'å±•ç¤ºï¼‰\n\n"
        "âš ï¸ æ³¨æ„ï¼šç¬”è®°ä¸­æ²¡æœ‰ç°æˆçš„æ ‡ç­¾ï¼Œéœ€è¦ä½ ä»æ ‡é¢˜å’Œæè¿°ä¸­åˆ†ææå–ä¸»é¢˜ã€‚\n"
        "ğŸ’¡ æå–è¯é¢˜æ—¶ä¼˜å…ˆé€‰æ‹©ï¼šé¢†åŸŸè¯ã€é«˜é¢‘è¯ã€è¡Œä¸šæœ¯è¯­ã€å“ç±»è¯ã€åœºæ™¯è¯ã€‚\n"
        "ä¾‹å¦‚ï¼šAIã€ç¼–ç¨‹ã€æ—…è¡Œã€ç¾é£Ÿã€ç§‘æ™®ã€èŒåœºã€Pythonã€æœºå™¨å­¦ä¹ ç­‰ã€‚\n\n"
        "ä¸¥æ ¼è¿”å›JSONæ ¼å¼ï¼š\n"
        '{"user_style": {"persona": "...", "tone": "...", "interests": ["..."]}, "content_topic": ["è¯é¢˜1", "è¯é¢˜2", ...]}'
    )

    user_msg = (
        f"ç”¨æˆ·ä¿¡æ¯:\n{user_desc}\n\n"
        f"ç¤ºä¾‹ç¬”è®°ï¼ˆå…±{len(notes)}æ¡ï¼‰ï¼š\n{notes_text}\n\n"
        "è¯·åˆ†æä»¥ä¸Šç¬”è®°ï¼Œæå–ç”¨æˆ·ç”»åƒå’Œå†…å®¹ä¸»é¢˜ï¼Œä»…è¾“å‡ºJSONå¯¹è±¡ã€‚"
    )

    return [{"role": "system", "content": system}, {"role": "user", "content": user_msg}]


def call_chat(api_key: str, messages: List[Dict[str, str]], provider: str = "openai") -> str:
    """è°ƒç”¨èŠå¤©æ¨¡å‹çš„é€šç”¨å‡½æ•°ã€‚

    å‚æ•°ï¼š
      - api_key: å¯¹åº”æœåŠ¡çš„ API Keyï¼ˆOpenAI æˆ– Deepseekï¼‰
      - messages: OpenAI-style çš„ messages åˆ—è¡¨
      - provider: 'openai' æˆ– 'deepseek'

    æ³¨æ„ï¼šæœ¬å‡½æ•°å‘æŒ‡å®šçš„ URL å‘é€ä¸ OpenAI å…¼å®¹çš„è¯·æ±‚ä½“ã€‚å¦‚æœ Deepseek çš„æ¥å£æ ¼å¼ä¸åŒï¼Œ
    è¯·å°† `DEEPSEEK_CHAT_URL` æŒ‡å‘ä¸€ä¸ªå…¼å®¹å±‚ï¼ˆproxyï¼‰ï¼Œæˆ–ä¿®æ”¹æœ¬å‡½æ•°ä»¥åŒ¹é… Deepseek çš„å®é™…è¯·æ±‚æ ¼å¼ã€‚
    """
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": CHAT_MODEL, "messages": messages, "temperature": 0.0}


    # æ ¹æ® provider é€‰æ‹©è¯·æ±‚ URL å’Œ æ¨¡å‹
    if provider == "deepseek":
        url = DEEPSEEK_CHAT_URL or os.environ.get("DEEPSEEK_CHAT_URL")
        payload["model"] = "deepseek-chat"
    else:
        url = OPENAI_CHAT_URL
        # payload["model"] already defaults to CHAT_MODEL (gpt-4o)


    if not url:
        raise RuntimeError(f"æœªé…ç½® provider '{provider}' çš„ chat URL")

    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()

    # è§£æè¿”å›ï¼šä¼˜å…ˆæŒ‰ OpenAI è¿”å›ç»“æ„è¯»å–ï¼›å¯¹ Deepseek æˆ–å…¶å®ƒå…¼å®¹ç»“æ„åšå…¼å®¹å¤„ç†
    if provider == "openai":
        return data["choices"][0]["message"]["content"]
    if "choices" in data and isinstance(data["choices"], list):
        c = data["choices"][0]
        if isinstance(c.get("message"), dict) and c["message"].get("content"):
            return c["message"]["content"]
        if c.get("text"):
            return c.get("text")

    # å…œåº•ï¼šå°è¯•è¯»å–é¡¶å±‚çš„ text å­—æ®µ
    if data.get("text"):
        return data.get("text")

    raise RuntimeError("æ— æ³•è§£æèŠå¤©æ¥å£è¿”å›å†…å®¹")


def extract_json(text: str) -> Any:
    """å°è¯•ä»æ¨¡å‹è¿”å›çš„æ–‡æœ¬ä¸­è§£æå‡ºç¬¬ä¸€ä¸ª JSON å¯¹è±¡ï¼ˆ{...}ï¼‰ã€‚

    æœ‰æ—¶å€™æ¨¡å‹ä¼šè¾“å‡ºé¢å¤–è¯´æ˜æ–‡æœ¬ï¼Œæœ¬å‡½æ•°ä¼šæå–ç¬¬ä¸€æ®µç¬¦åˆ JSON è¯­æ³•çš„å­ä¸²å¹¶è§£æã€‚
    """
    try:
        return json.loads(text)
    except Exception:
        m = re.search(r"\{[\s\S]*\}", text)
        if m:
            try:
                return json.loads(m.group(0))
            except Exception:
                pass
    raise ValueError("æœªåœ¨åŠ©æ‰‹è¿”å›ä¸­æ‰¾åˆ°å¯è§£æçš„ JSON")


def call_embeddings(api_key: str, inputs: List[str], provider: str = "openai") -> List[List[float]]:
    """è°ƒç”¨å‘é‡åŒ–ï¼ˆembeddingsï¼‰æ¥å£çš„é€šç”¨å‡½æ•°ã€‚

    å‚æ•°ï¼š
      - api_key: å¯¹åº”æœåŠ¡çš„ API Keyï¼ˆOpenAI æˆ– Deepseekï¼‰
      - inputs: å¾…å‘é‡åŒ–çš„æ–‡æœ¬åˆ—è¡¨
      - provider: 'openai' æˆ– 'deepseek'

    æ³¨æ„ï¼šæœ¬å‡½æ•°å‘é€ä¸ OpenAI å…¼å®¹çš„è¯·æ±‚ä½“ï¼›å¦‚æœ Deepseek è¦æ±‚ä¸åŒï¼Œè¯·ä¿®æ”¹æ­¤å¤„æˆ–ä½¿ç”¨ proxyã€‚
    """
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": EMBED_MODEL, "input": inputs}

    if provider == "deepseek":
        url = DEEPSEEK_EMBED_URL or os.environ.get("DEEPSEEK_EMBED_URL")
    else:
        url = OPENAI_EMBED_URL

    if not url:
        raise RuntimeError(f"æœªé…ç½® provider '{provider}' çš„ embeddings URL")

    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()

    # è§£æ OpenAI é£æ ¼çš„è¿”å›
    if "data" in data and isinstance(data["data"], list):
        return [d.get("embedding") for d in data["data"]]

    # Deepseek é£æ ¼çš„å…œåº•è§£æï¼ˆå‡è®¾è¿”å›é¡¶å±‚çš„ embeddings åˆ—è¡¨ï¼‰
    if data.get("embeddings") and isinstance(data.get("embeddings"), list):
        return data.get("embeddings")

    raise RuntimeError("æ— æ³•è§£æ embeddings æ¥å£çš„è¿”å›å†…å®¹")


def main():
    parser = argparse.ArgumentParser(description="Generate user profile via GPT and embeddings from a snapshot JSON")
    parser.add_argument("--snapshot", help="Path to snapshot JSON (default: latest in snapshots/)")
    parser.add_argument("--out", default="analyses", help="Output directory to save profile and embeddings")
    args = parser.parse_args()

    snap_dir = Path(__file__).resolve().parent / "snapshots"
    snap_path = Path(args.snapshot) if args.snapshot else find_latest_snapshot(snap_dir)
    if not snap_path or not snap_path.exists():
        raise SystemExit(f"Snapshot not found: {snap_path}")

    snapshot = load_snapshot(snap_path)
    user = snapshot.get("user") or {}
    notes = snapshot.get("notes") or []

    user_desc = user.get("desc", "")

    provider = os.environ.get("AI_PROVIDER", "openai")
    api_key = None
    if provider == "openai":
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼Œå…¶æ¬¡ä½¿ç”¨è„šæœ¬é¡¶éƒ¨çš„ DEFAULT_OPENAI_API_KEY
        api_key = os.environ.get("OPENAI_API_KEY") or DEFAULT_OPENAI_API_KEY
    elif provider == "deepseek":
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEYï¼Œå…¶æ¬¡ä½¿ç”¨è„šæœ¬é¡¶éƒ¨çš„ DEFAULT_DEEPSEEK_API_KEY
        api_key = os.environ.get("DEEPSEEK_API_KEY") or DEFAULT_DEEPSEEK_API_KEY
    else:
        raise SystemExit(f"Unknown provider: {provider}. Set AI_PROVIDER=openai|deepseek or set appropriate env vars.")

    if not api_key:
        raise SystemExit(f"Please set API key for provider '{provider}' in environment or fill the DEFAULT_* variable in the script.")

    messages = build_prompt_for_profile(user_desc, notes)
    print(f"Calling {provider} GPT to generate profile...")
    chat_text = call_chat(api_key, messages, provider=provider)
    try:
        profile = extract_json(chat_text)
    except Exception as e:
        print("Failed to parse assistant response as JSON. Raw response:\n", chat_text)
        raise

    # Save profile
    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)
    profile_path = out_dir / (snap_path.stem + "__profile.json")
    with open(profile_path, "w", encoding="utf-8") as f:
        json.dump(profile, f, ensure_ascii=False, indent=2)
    print(f"Profile saved to {profile_path}")

    # Build embedding inputs: one for user_style JSON string, one per note (title+desc+tags)
    user_style_text = json.dumps(profile.get("user_style", {}), ensure_ascii=False)
    note_texts = []
    note_ids = []
    for n in notes:
        tags = n.get("tag_list") or []
        if isinstance(tags, dict):
            tags = list(tags.values())
        tags_s = ", ".join(tags) if tags else ""
        txt = f"Title: {n.get('title','')}\nDesc: {n.get('desc','')}\nTags: {tags_s}"
        note_texts.append(txt)
        note_ids.append(n.get("note_id") or n.get("_id") or None)

    embed_inputs = [user_style_text] + note_texts
    print(f"Requesting embeddings for {len(embed_inputs)} items using {provider}...")
    embeddings = call_embeddings(api_key, embed_inputs, provider=provider)

    # Save embeddings: first is user_style, rest correspond to note_ids
    embeds_out = {
        "snapshot": str(snap_path.name),
        "generated_at": datetime.utcnow().isoformat(),
        "user_style_embedding": embeddings[0],
        "notes": [
            {"note_id": nid, "embedding": emb}
            for nid, emb in zip(note_ids, embeddings[1:])
        ],
    }
    embed_path = out_dir / (snap_path.stem + "__embeddings.json")
    with open(embed_path, "w", encoding="utf-8") as f:
        json.dump(embeds_out, f, ensure_ascii=False)
    print(f"Embeddings saved to {embed_path}")


def analyze_user_profile(user_info: Dict[str, Any], notes: List[Dict[str, Any]], embedding_model: FlagModel = None) -> Dict[str, Any]:
    """
    åˆ†æç”¨æˆ·ç”»åƒå¹¶ç”Ÿæˆembeddingï¼ˆä¾›pipeline.pyè°ƒç”¨ï¼‰
    
    Args:
        user_info: ç”¨æˆ·ä¿¡æ¯å­—å…¸ï¼ˆä»notes[0]['user']æå–ï¼‰
        notes: ç¬”è®°åˆ—è¡¨
        embedding_model: FlagModelå®ä¾‹ï¼Œç”¨äºç”Ÿæˆæœ¬åœ°embedding
        
    Returns:
        åŒ…å«profileå’Œembeddingçš„å­—å…¸
    """
    # ä½¿ç”¨Deepseek
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    provider = "deepseek"
    
    # æ„å»ºç”¨æˆ·æè¿°
    user_desc = f"User: {user_info.get('nickname', 'Unknown')}\nFollowers: {user_info.get('fans', 0)}"
    
    # æ„å»ºprompt
    messages = build_prompt_for_profile(user_desc, notes)
    
    # è°ƒç”¨chat APIç”Ÿæˆprofile
    response_text = call_chat(api_key, messages, provider=provider)
    profile = extract_json(response_text)
    
    if not profile:
        raise ValueError("æ— æ³•è§£æDeepSeekè¿”å›çš„JSON")
    
    # ç”Ÿæˆå®Œæ•´çš„profile_dataç»“æ„
    profile_data = {
        "user_basic": {
            "user_id": user_info.get('userid', user_info.get('user_id', '')),
            "nickname": user_info.get('nickname', ''),
            "fans": user_info.get('fans', 0),
            "gender": "æœªçŸ¥",
            "avatar": user_info.get('images', ''),
            "desc": "",
            "interaction": 0,
            "ip_location": "",
            "last_modify_ts": int(datetime.now().timestamp() * 1000)
        },
        "content_topics": profile.get("content_topic", []),
        "content_style": [],
        "audience": [],
        "value_points": [],
        "content_clusters": []
    }
    
    # æå–user_style
    user_style = profile.get("user_style", {})
    if isinstance(user_style, dict):
        persona = user_style.get("persona", "")
        tone = user_style.get("tone", "")
        interests = user_style.get("interests", [])
        
        if isinstance(interests, list):
            profile_data["content_style"] = interests
        
        # æ„å»ºembeddingæ–‡æœ¬
        user_style_text = f"{persona} {tone} {' '.join(interests) if isinstance(interests, list) else ''}"
    else:
        user_style_text = str(user_style)
    
    # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆembedding
    print("  ç”Ÿæˆembedding...")
    if embedding_model is None:
        # å¦‚æœæ²¡æœ‰ä¼ å…¥modelï¼Œä¸´æ—¶åˆ›å»ºä¸€ä¸ª
        embedding_model = FlagModel(
            "BAAI/bge-small-zh-v1.5",
            query_instruction_for_retrieval="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š",
            use_fp16=True
        )
    
    vec = embedding_model.encode([user_style_text])  # è¿”å› numpy array shape (1, dim)
    if hasattr(vec, "tolist"):
        emb = vec.tolist()[0]
    else:
        emb = np.array(vec).tolist()
    
    profile_data["user_style_embedding"] = emb
    
    return profile_data


if __name__ == "__main__":
    main()
